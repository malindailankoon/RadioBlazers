options:
  parameters:
    author: ''
    catch_exceptions: 'True'
    category: '[GRC Hier Blocks]'
    cmake_opt: ''
    comment: ''
    copyright: ''
    description: ''
    gen_cmake: 'On'
    gen_linking: dynamic
    generate_options: qt_gui
    hier_block_src_path: '.:'
    id: threading1
    max_nouts: '0'
    output_language: python
    placement: (0,0)
    qt_qss_theme: ''
    realtime_scheduling: ''
    run: 'True'
    run_command: '{python} -u {filename}'
    run_options: prompt
    sizing_mode: fixed
    thread_safe_setters: ''
    title: Not titled yet
    window_size: (1000,1000)
  states:
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [8, 8]
    rotation: 0
    state: enabled

blocks:
- name: access_key
  id: variable
  parameters:
    comment: ''
    value: '''101010101010101010101010101010100010110111010100'''
  states:
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [1856, 28.0]
    rotation: 0
    state: enabled
- name: nfilts
  id: variable
  parameters:
    comment: ''
    value: '32'
  states:
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [928, 36.0]
    rotation: 0
    state: enabled
- name: qpsk
  id: variable_constellation_rect
  parameters:
    comment: ''
    const_points: '[0.707+0.707j, -0.707+0.707j, -0.707-0.707j, 0.707-0.707j]'
    imag_sect: '2'
    precision: '8'
    real_sect: '2'
    rot_sym: '4'
    soft_dec_lut: None
    sym_map: '[0, 1, 2, 3]'
    w_imag_sect: '1'
    w_real_sect: '1'
  states:
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [16, 348.0]
    rotation: 0
    state: enabled
- name: rrc_taps
  id: variable
  parameters:
    comment: ''
    value: firdes.root_raised_cosine(nfilts, nfilts, 1.0/float(sps), 0.35, 11*sps*nfilts)
  states:
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [1272, 28.0]
    rotation: 0
    state: enabled
- name: samp_rate
  id: variable
  parameters:
    comment: ''
    value: '32000'
  states:
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [200, 12]
    rotation: 0
    state: enabled
- name: sps
  id: variable
  parameters:
    comment: Samples Per Symbol
    value: '4'
  states:
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [1472, 28.0]
    rotation: 0
    state: enabled
- name: taps
  id: variable
  parameters:
    comment: ''
    value: '[1.0, 0.25-0.25j, 0.50 + 0.10j, -0.3 + 0.2j]'
  states:
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [1024, 36.0]
    rotation: 0
    state: enabled
- name: variable_adaptive_algorithm_0
  id: variable_adaptive_algorithm
  parameters:
    comment: ''
    cons: qpsk
    delta: '10.0'
    ffactor: '0.99'
    modulus: '4'
    step_size: '.0001'
    type: cma
  states:
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [1624, 20.0]
    rotation: 0
    state: enabled
- name: blocks_message_debug_0
  id: blocks_message_debug
  parameters:
    affinity: ''
    alias: ''
    comment: ''
    en_uvec: 'True'
    log_level: info
  states:
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [1608, 868.0]
    rotation: 0
    state: enabled
- name: blocks_message_debug_0_0
  id: blocks_message_debug
  parameters:
    affinity: ''
    alias: ''
    comment: ''
    en_uvec: 'True'
    log_level: info
  states:
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [1296, 244.0]
    rotation: 0
    state: enabled
- name: blocks_message_strobe_0
  id: blocks_message_strobe
  parameters:
    affinity: ''
    alias: ''
    comment: ''
    maxoutbuf: '0'
    minoutbuf: '0'
    msg: pmt.intern("2:Hello from A")
    period: '1000'
  states:
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [112, 224.0]
    rotation: 0
    state: enabled
- name: blocks_message_strobe_0_0
  id: blocks_message_strobe
  parameters:
    affinity: ''
    alias: ''
    comment: ''
    maxoutbuf: '0'
    minoutbuf: '0'
    msg: pmt.intern("1:Hello from B")
    period: '1000'
  states:
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [208, 856.0]
    rotation: 0
    state: enabled
- name: epy_block_0
  id: epy_block
  parameters:
    _source_code: "\"\"\"\nEmbedded Python Block for GNU Radio - Mesh Network Packet\
      \ Communication\nImplements packetization, Stop-and-Wait ARQ, and ALOHA collision\
      \ avoidance\nNo external CRC module required - implements CRC-16 CCITT manually\n\
      \"\"\"\n\nimport numpy as np\nfrom gnuradio import gr\nimport pmt\nimport threading\n\
      import queue\nimport time\nimport random\nimport struct\n\nclass blk(gr.sync_block):\n\
      \    \"\"\"\n    Mesh Network Packet Communication Block\n    Handles packet\
      \ transmission/reception with Stop-and-Wait ARQ\n    \"\"\"\n    \n    def __init__(self,\
      \ node_id=1, aloha_prob=0.3, timeout=1.0, max_retries=3):\n        \"\"\"\n\
      \        Arguments:\n            node_id: Unique identifier for this node (1-255)\n\
      \            aloha_prob: Transmission probability for ALOHA (0.0-1.0)\n    \
      \        timeout: ARQ timeout in seconds\n            max_retries: Maximum retransmission\
      \ attempts\n        \"\"\"\n        gr.sync_block.__init__(\n            self,\n\
      \            name='Mesh Packet Comm',\n            in_sig=None,\n          \
      \  out_sig=None\n        )\n        \n        # Node configuration\n       \
      \ self.node_id = node_id\n        self.aloha_prob = aloha_prob\n        self.timeout\
      \ = timeout\n        self.max_retries = max_retries\n        \n        # Packet\
      \ parameters\n        self.PREAMBLE = bytes([0xAA, 0xAA, 0xAA, 0xAA])\n    \
      \    self.SYNC_WORD = bytes([0x2D, 0xD4])\n        self.MAX_PAYLOAD = 255\n\
      \        self.HEADER_SIZE = 8  # preamble(4) + sync(2) + src(1) + dst(1)\n \
      \       self.CRC_SIZE = 2\n        \n        # Packet types\n        self.PKT_DATA\
      \ = 0x01\n        self.PKT_ACK = 0x02\n        \n        # CRC-16 CCITT lookup\
      \ table\n        self.crc_table = self.generate_crc_table()\n        \n    \
      \    # State management\n        self.tx_queue = queue.Queue()\n        self.rx_queue\
      \ = queue.Queue()\n        self.ack_queue = queue.Queue()\n        self.pending_ack\
      \ = {}\n        self.seq_num_tx = 0\n        self.seq_num_rx = {}\n        self.rx_buffer\
      \ = bytes()\n        \n        # Statistics\n        self.stats = {\n      \
      \      'packets_sent': 0,\n            'packets_received': 0,\n            'acks_sent':\
      \ 0,\n            'acks_received': 0,\n            'retransmissions': 0,\n \
      \           'crc_errors': 0\n        }\n        \n        # Threading\n    \
      \    self.running = True\n        self.tx_thread = threading.Thread(target=self.tx_handler)\n\
      \        self.rx_thread = threading.Thread(target=self.rx_handler)\n       \
      \ self.lock = threading.Lock()\n        \n        # Message ports\n        self.message_port_register_in(pmt.intern('msg_in'))\n\
      \        self.message_port_register_in(pmt.intern('pdu_in'))\n        self.message_port_register_out(pmt.intern('msg_out'))\n\
      \        self.message_port_register_out(pmt.intern('pdu_out'))\n        \n \
      \       # Set message handlers\n        self.set_msg_handler(pmt.intern('msg_in'),\
      \ self.handle_msg_in)\n        self.set_msg_handler(pmt.intern('pdu_in'), self.handle_pdu_in)\n\
      \        \n        # Start threads\n        self.tx_thread.start()\n       \
      \ self.rx_thread.start()\n        \n        print(f\"[Node {self.node_id}] Initialized\
      \ - Ready for communication\")\n    \n    def generate_crc_table(self):\n  \
      \      \"\"\"Generate CRC-16 CCITT lookup table\"\"\"\n        poly = 0x1021\n\
      \        table = []\n        for i in range(256):\n            crc = i << 8\n\
      \            for j in range(8):\n                if crc & 0x8000:\n        \
      \            crc = ((crc << 1) ^ poly) & 0xFFFF\n                else:\n   \
      \                 crc = (crc << 1) & 0xFFFF\n            table.append(crc)\n\
      \        return table\n    \n    def calculate_crc16(self, data):\n        \"\
      \"\"Calculate CRC-16 CCITT for given data\"\"\"\n        crc = 0xFFFF\n    \
      \    for byte in data:\n            tbl_idx = ((crc >> 8) ^ byte) & 0xFF\n \
      \           crc = ((crc << 8) ^ self.crc_table[tbl_idx]) & 0xFFFF\n        return\
      \ crc\n    \n    def handle_msg_in(self, msg):\n        \"\"\"Handle incoming\
      \ messages from GUI/application\"\"\"\n        try:\n            # Handle string\
      \ messages directly\n            if pmt.is_symbol(msg):\n                # Simple\
      \ text message format: \"dst_id:message\"\n                text = pmt.symbol_to_string(msg)\n\
      \                if ':' in text:\n                    parts = text.split(':',\
      \ 1)\n                    try:\n                        dst_id = int(parts[0])\n\
      \                        data = parts[1].encode()\n                        self.tx_queue.put({'dst':\
      \ dst_id, 'data': data, 'type': self.PKT_DATA})\n                        print(f\"\
      [Node {self.node_id}] Queued message to {dst_id}: {parts[1]}\")\n          \
      \          except ValueError:\n                        print(f\"[Node {self.node_id}]\
      \ Invalid destination ID\")\n            \n            # Handle dictionary messages\n\
      \            elif pmt.is_dict(msg):\n                meta = pmt.to_python(msg)\n\
      \                if 'dst' in meta and 'data' in meta:\n                    dst_id\
      \ = meta['dst']\n                    data = meta['data'].encode() if isinstance(meta['data'],\
      \ str) else meta['data']\n                    self.tx_queue.put({'dst': dst_id,\
      \ 'data': data, 'type': self.PKT_DATA})\n                    print(f\"[Node\
      \ {self.node_id}] Queued message to {dst_id}\")\n            \n            #\
      \ Handle pair messages (PDU format)\n            elif pmt.is_pair(msg):\n  \
      \              meta = pmt.to_python(pmt.car(msg))\n                data = pmt.to_python(pmt.cdr(msg))\n\
      \                if isinstance(meta, dict) and 'dst' in meta:\n            \
      \        dst_id = meta['dst']\n                    if isinstance(data, str):\n\
      \                        data = data.encode()\n                    elif isinstance(data,\
      \ list):\n                        data = bytes(data)\n                    self.tx_queue.put({'dst':\
      \ dst_id, 'data': data, 'type': self.PKT_DATA})\n                    print(f\"\
      [Node {self.node_id}] Queued message to {dst_id}\")\n                    \n\
      \        except Exception as e:\n            print(f\"[Node {self.node_id}]\
      \ Error handling msg_in: {e}\")\n    \n    def handle_pdu_in(self, pdu):\n \
      \       \"\"\"Handle incoming PDUs from demodulator\"\"\"\n        try:\n  \
      \          # Extract PDU data\n            if pmt.is_pair(pdu):\n          \
      \      meta = pmt.car(pdu)\n                data = pmt.cdr(pdu)\n          \
      \      \n                # Convert to bytes\n                if pmt.is_u8vector(data):\n\
      \                    print(\"loop run\")\t\n                    rx_bytes = bytes(pmt.u8vector_elements(data))\t\
      \n                    self.rx_queue.put(rx_bytes)\n                elif pmt.is_uniform_vector(data):\n\
      \                    # Handle float32 or other vector types\n              \
      \      elements = pmt.to_python(data)\n                    # Convert to bytes\
      \ (assuming 8-bit symbols)\n                    rx_bytes = bytes([int(x) & 0xFF\
      \ for x in elements])\n                    self.rx_queue.put(rx_bytes)\n   \
      \                 \n        except Exception as e:\n            print(f\"[Node\
      \ {self.node_id}] Error handling pdu_in: {e}\")\n    \n    def create_packet(self,\
      \ dst_id, seq_num, pkt_type, payload=b''):\n        \"\"\"Create a packet with\
      \ headers and CRC\"\"\"\n        packet = bytearray()\n        \n        # Add\
      \ preamble and sync word\n        packet.extend(self.PREAMBLE)\n        packet.extend(self.SYNC_WORD)\n\
      \        \n        # Add header\n        packet.append(self.node_id)  # Source\
      \ ID\n        packet.append(dst_id)         # Destination ID\n        packet.append(seq_num)\
      \        # Sequence number\n        packet.append(pkt_type)       # Packet type\n\
      \        packet.append(len(payload))   # Payload length\n        \n        #\
      \ Add payload\n        if payload:\n            packet.extend(payload[:self.MAX_PAYLOAD])\n\
      \        \n        # Calculate and add CRC16\n        crc_data = bytes(packet[len(self.PREAMBLE)\
      \ + len(self.SYNC_WORD):])\n        crc_val = self.calculate_crc16(crc_data)\n\
      \        packet.extend(struct.pack('>H', crc_val))\n        \n        return\
      \ bytes(packet)\n    \n    def parse_packet(self, data):\n        \"\"\"Parse\
      \ received packet and validate CRC\"\"\"\n        try:\n            # Find sync\
      \ word\n            sync_idx = data.find(self.SYNC_WORD)\n            if sync_idx\
      \ == -1:\n                return None\n            \n            # Check minimum\
      \ packet size\n            start_idx = sync_idx + len(self.SYNC_WORD)\n    \
      \        if len(data) < start_idx + 5 + self.CRC_SIZE:\n                return\
      \ None\n            \n            # Extract header fields\n            src_id\
      \ = data[start_idx]\n            dst_id = data[start_idx + 1]\n            seq_num\
      \ = data[start_idx + 2]\n            pkt_type = data[start_idx + 3]\n      \
      \      payload_len = data[start_idx + 4]\n            \n            # Check\
      \ if we have complete packet\n            total_len = start_idx + 5 + payload_len\
      \ + self.CRC_SIZE\n            if len(data) < total_len:\n                return\
      \ None\n            \n            # Extract payload and CRC\n            payload\
      \ = data[start_idx + 5:start_idx + 5 + payload_len]\n            rx_crc = struct.unpack('>H',\
      \ data[total_len - self.CRC_SIZE:total_len])[0]\n            \n            #\
      \ Verify CRC\n            crc_data = data[start_idx:total_len - self.CRC_SIZE]\n\
      \            calc_crc = self.calculate_crc16(crc_data)\n            \n     \
      \       if rx_crc != calc_crc:\n                self.stats['crc_errors'] +=\
      \ 1\n                print(f\"[Node {self.node_id}] CRC mismatch (expected:\
      \ {calc_crc:04X}, got: {rx_crc:04X})\")\n                return None\n     \
      \       \n            return {\n                'src': src_id,\n           \
      \     'dst': dst_id,\n                'seq': seq_num,\n                'type':\
      \ pkt_type,\n                'payload': payload,\n                'consumed':\
      \ total_len\n            }\n        except Exception as e:\n            print(f\"\
      [Node {self.node_id}] Error parsing packet: {e}\")\n            return None\n\
      \    \n    def tx_handler(self):\n        \"\"\"Thread for handling packet transmission\
      \ with ARQ\"\"\"\n        while self.running:\n            try:\n          \
      \      # Get message from queue (with timeout for thread safety)\n         \
      \       try:\n                    msg = self.tx_queue.get(timeout=0.1)\n   \
      \             except queue.Empty:\n                    continue\n          \
      \      \n                # ALOHA: Random backoff\n                if random.random()\
      \ > self.aloha_prob:\n                    backoff_time = random.uniform(0.1,\
      \ 0.5)\n                    print(f\"[Node {self.node_id}] ALOHA backoff {backoff_time:.2f}s\"\
      )\n                    time.sleep(backoff_time)\n                    # Re-queue\
      \ the message\n                    self.tx_queue.put(msg)\n                \
      \    continue\n                \n                # Prepare packet\n        \
      \        with self.lock:\n                    seq_num = self.seq_num_tx\n  \
      \                  self.seq_num_tx = (self.seq_num_tx + 1) % 256\n         \
      \       \n                packet = self.create_packet(\n                   \
      \ msg['dst'],\n                    seq_num,\n                    msg['type'],\n\
      \                    msg.get('data', b'')\n                )\n             \
      \   \n                # Stop-and-Wait ARQ\n                retries = 0\n   \
      \             ack_received = False\n                \n                while\
      \ retries < self.max_retries and not ack_received:\n                    # Transmit\
      \ packet\n                    print(f\"[Node {self.node_id}] TX: Sending packet\
      \ seq={seq_num} to node {msg['dst']} (attempt {retries + 1})\")\n          \
      \          self.transmit_packet(packet)\n                    self.stats['packets_sent']\
      \ += 1\n                    \n                    if retries > 0:\n        \
      \                self.stats['retransmissions'] += 1\n                    \n\
      \                    # Wait for ACK\n                    ack_key = f\"{msg['dst']}_{seq_num}\"\
      \n                    timeout_time = time.time() + self.timeout\n          \
      \          \n                    while time.time() < timeout_time:\n       \
      \                 try:\n                            ack = self.ack_queue.get(timeout=0.1)\n\
      \                            if ack['key'] == ack_key:\n                   \
      \             ack_received = True\n                                self.stats['acks_received']\
      \ += 1\n                                print(f\"[Node {self.node_id}] TX: ACK\
      \ received for seq={seq_num}\")\n                                break\n   \
      \                     except queue.Empty:\n                            pass\n\
      \                    \n                    if not ack_received:\n          \
      \              retries += 1\n                        if retries < self.max_retries:\n\
      \                            print(f\"[Node {self.node_id}] TX: Timeout, retry\
      \ {retries}/{self.max_retries}\")\n                \n                if not\
      \ ack_received:\n                    print(f\"[Node {self.node_id}] TX: Failed\
      \ to deliver packet seq={seq_num} after {self.max_retries} attempts\")\n   \
      \                 \n            except Exception as e:\n                print(f\"\
      [Node {self.node_id}] TX handler error: {e}\")\n    \n    def rx_handler(self):\n\
      \        \"\"\"Thread for handling packet reception\"\"\"\n        while self.running:\n\
      \            try:\n                # Get received data\n                try:\n\
      \                    rx_data = self.rx_queue.get(timeout=0.1)\n            \
      \    except queue.Empty:\n                    continue\n                \n \
      \               # Add to buffer\n                self.rx_buffer += rx_data\n\
      \                \n                # Try to parse packets from buffer\n    \
      \            while len(self.rx_buffer) > 0:\n                    pkt = self.parse_packet(self.rx_buffer)\n\
      \                    \n                    if pkt is None:\n               \
      \         # No valid packet found, remove first byte and try again\n       \
      \                 if len(self.rx_buffer) > 1:\n                            self.rx_buffer\
      \ = self.rx_buffer[1:]\n                        else:\n                    \
      \        self.rx_buffer = bytes()\n                        continue\n      \
      \              \n                    # Remove processed packet from buffer\n\
      \                    self.rx_buffer = self.rx_buffer[pkt['consumed']:]\n   \
      \                 \n                    # Check if packet is for this node or\
      \ broadcast\n                    if pkt['dst'] != self.node_id and pkt['dst']\
      \ != 0xFF:\n                        print(f\"[Node {self.node_id}] RX: Packet\
      \ not for us (dst={pkt['dst']})\")\n                        continue\n     \
      \               \n                    # Handle based on packet type\n      \
      \              if pkt['type'] == self.PKT_DATA:\n                        self.stats['packets_received']\
      \ += 1\n                        print(f\"[Node {self.node_id}] RX: Data packet\
      \ from node {pkt['src']}, seq={pkt['seq']}\")\n                        \n  \
      \                      # Check for duplicate\n                        is_duplicate\
      \ = False\n                        if pkt['src'] in self.seq_num_rx:\n     \
      \                       if self.seq_num_rx[pkt['src']] == pkt['seq']:\n    \
      \                            print(f\"[Node {self.node_id}] RX: Duplicate packet\
      \ detected\")\n                                is_duplicate = True\n       \
      \                 \n                        self.seq_num_rx[pkt['src']] = pkt['seq']\n\
      \                        \n                        # Send ACK\n            \
      \            ack_packet = self.create_packet(\n                            pkt['src'],\n\
      \                            pkt['seq'],\n                            self.PKT_ACK\n\
      \                        )\n                        print(f\"[Node {self.node_id}]\
      \ RX: Sending ACK for seq={pkt['seq']}\")\n                        self.transmit_packet(ack_packet)\n\
      \                        self.stats['acks_sent'] += 1\n                    \
      \    \n                        # Forward to application if not duplicate\n \
      \                       if not is_duplicate:\n                            self.forward_to_app(pkt['src'],\
      \ pkt['payload'])\n                        \n                    elif pkt['type']\
      \ == self.PKT_ACK:\n                        print(f\"[Node {self.node_id}] RX:\
      \ ACK packet from node {pkt['src']}, seq={pkt['seq']}\")\n                 \
      \       # Process ACK\n                        ack_key = f\"{pkt['src']}_{pkt['seq']}\"\
      \n                        self.ack_queue.put({'key': ack_key})\n           \
      \             \n            except Exception as e:\n                print(f\"\
      [Node {self.node_id}] RX handler error: {e}\")\n    \n    def transmit_packet(self,\
      \ packet):\n        \"\"\"Send packet to physical layer\"\"\"\n        try:\n\
      \            # Convert to PDU format\n            vec = pmt.init_u8vector(len(packet),\
      \ list(packet))\n            pdu = pmt.cons(pmt.PMT_NIL, vec)\n            \n\
      \            # Send to modulator\n            self.message_port_pub(pmt.intern('pdu_out'),\
      \ pdu)\n            \n        except Exception as e:\n            print(f\"\
      [Node {self.node_id}] Error transmitting packet: {e}\")\n    \n    def forward_to_app(self,\
      \ src_id, data):\n        \"\"\"Forward received data to application/GUI\"\"\
      \"\n        try:\n            # Decode message\n            message = data.decode('utf-8',\
      \ errors='ignore')\n            \n            # Create formatted output string\n\
      \            output = f\"[From Node {src_id}]: {message}\"\n            \n \
      \           # Send as simple string message\n            msg = pmt.intern(output)\n\
      \            self.message_port_pub(pmt.intern('msg_out'), msg)\n           \
      \ \n            # Also send as dictionary for more complex processing\n    \
      \        meta = pmt.make_dict()\n            meta = pmt.dict_add(meta, pmt.intern(\"\
      src\"), pmt.from_long(src_id))\n            meta = pmt.dict_add(meta, pmt.intern(\"\
      data\"), pmt.intern(message))\n            \n            print(f\"[Node {self.node_id}]\
      \ Message delivered: {output}\")\n            \n        except Exception as\
      \ e:\n            print(f\"[Node {self.node_id}] Error forwarding to app: {e}\"\
      )\n    \n    def work(self, input_items, output_items):\n        \"\"\"Main\
      \ work function (not used for message passing blocks)\"\"\"\n        return\
      \ 0\n    \n    def stop(self):\n        \"\"\"Clean shutdown\"\"\"\n       \
      \ print(f\"\\n[Node {self.node_id}] Statistics:\")\n        print(f\"  Packets\
      \ sent: {self.stats['packets_sent']}\")\n        print(f\"  Packets received:\
      \ {self.stats['packets_received']}\")\n        print(f\"  ACKs sent: {self.stats['acks_sent']}\"\
      )\n        print(f\"  ACKs received: {self.stats['acks_received']}\")\n    \
      \    print(f\"  Retransmissions: {self.stats['retransmissions']}\")\n      \
      \  print(f\"  CRC errors: {self.stats['crc_errors']}\")\n        \n        self.running\
      \ = False\n        if self.tx_thread.is_alive():\n            self.tx_thread.join()\n\
      \        if self.rx_thread.is_alive():\n            self.rx_thread.join()\n\
      \        return True\n"
    affinity: ''
    alias: ''
    aloha_prob: '0.5'
    comment: ''
    max_retries: '3'
    maxoutbuf: '0'
    minoutbuf: '0'
    node_id: '1'
    timeout: '1'
  states:
    _io_cache: ('Mesh Packet Comm', 'blk', [('node_id', '1'), ('aloha_prob', '0.3'),
      ('timeout', '1.0'), ('max_retries', '3')], [('msg_in', 'message', 1), ('pdu_in',
      'message', 1)], [('pdu_out', 'message', 1), ('msg_out', 'message', 1)], '\n    Mesh
      Network Packet Communication Block\n    Handles packet transmission/reception
      with Stop-and-Wait ARQ\n    ', ['aloha_prob', 'max_retries', 'node_id', 'timeout'])
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [720, 368.0]
    rotation: 0
    state: enabled
- name: epy_block_0_0
  id: epy_block
  parameters:
    _source_code: "\"\"\"\nEmbedded Python Block for GNU Radio - Mesh Network Packet\
      \ Communication\nImplements packetization, Stop-and-Wait ARQ, and ALOHA collision\
      \ avoidance\nNo external CRC module required - implements CRC-16 CCITT manually\n\
      \"\"\"\n\nimport numpy as np\nfrom gnuradio import gr\nimport pmt\nimport threading\n\
      import queue\nimport time\nimport random\nimport struct\n\nclass blk(gr.sync_block):\n\
      \    \"\"\"\n    Mesh Network Packet Communication Block\n    Handles packet\
      \ transmission/reception with Stop-and-Wait ARQ\n    \"\"\"\n    \n    def __init__(self,\
      \ node_id=1, aloha_prob=0.3, timeout=1.0, max_retries=3):\n        \"\"\"\n\
      \        Arguments:\n            node_id: Unique identifier for this node (1-255)\n\
      \            aloha_prob: Transmission probability for ALOHA (0.0-1.0)\n    \
      \        timeout: ARQ timeout in seconds\n            max_retries: Maximum retransmission\
      \ attempts\n        \"\"\"\n        gr.sync_block.__init__(\n            self,\n\
      \            name='Mesh Packet Comm',\n            in_sig=None,\n          \
      \  out_sig=None\n        )\n        \n        # Node configuration\n       \
      \ self.node_id = node_id\n        self.aloha_prob = aloha_prob\n        self.timeout\
      \ = timeout\n        self.max_retries = max_retries\n        \n        # Packet\
      \ parameters\n        self.PREAMBLE = bytes([0xAA, 0xAA, 0xAA, 0xAA])\n    \
      \    self.SYNC_WORD = bytes([0x2D, 0xD4])\n        self.MAX_PAYLOAD = 255\n\
      \        self.HEADER_SIZE = 8  # preamble(4) + sync(2) + src(1) + dst(1)\n \
      \       self.CRC_SIZE = 2\n        \n        # Packet types\n        self.PKT_DATA\
      \ = 0x01\n        self.PKT_ACK = 0x02\n        \n        # CRC-16 CCITT lookup\
      \ table\n        self.crc_table = self.generate_crc_table()\n        \n    \
      \    # State management\n        self.tx_queue = queue.Queue()\n        self.rx_queue\
      \ = queue.Queue()\n        self.ack_queue = queue.Queue()\n        self.pending_ack\
      \ = {}\n        self.seq_num_tx = 0\n        self.seq_num_rx = {}\n        self.rx_buffer\
      \ = bytes()\n        \n        # Statistics\n        self.stats = {\n      \
      \      'packets_sent': 0,\n            'packets_received': 0,\n            'acks_sent':\
      \ 0,\n            'acks_received': 0,\n            'retransmissions': 0,\n \
      \           'crc_errors': 0\n        }\n        \n        # Threading\n    \
      \    self.running = True\n        self.tx_thread = threading.Thread(target=self.tx_handler)\n\
      \        self.rx_thread = threading.Thread(target=self.rx_handler)\n       \
      \ self.lock = threading.Lock()\n        \n        # Message ports\n        self.message_port_register_in(pmt.intern('msg_in'))\n\
      \        self.message_port_register_in(pmt.intern('pdu_in'))\n        self.message_port_register_out(pmt.intern('msg_out'))\n\
      \        self.message_port_register_out(pmt.intern('pdu_out'))\n        \n \
      \       # Set message handlers\n        self.set_msg_handler(pmt.intern('msg_in'),\
      \ self.handle_msg_in)\n        self.set_msg_handler(pmt.intern('pdu_in'), self.handle_pdu_in)\n\
      \        \n        # Start threads\n        self.tx_thread.start()\n       \
      \ self.rx_thread.start()\n        \n        print(f\"[Node {self.node_id}] Initialized\
      \ - Ready for communication\")\n    \n    def generate_crc_table(self):\n  \
      \      \"\"\"Generate CRC-16 CCITT lookup table\"\"\"\n        poly = 0x1021\n\
      \        table = []\n        for i in range(256):\n            crc = i << 8\n\
      \            for j in range(8):\n                if crc & 0x8000:\n        \
      \            crc = ((crc << 1) ^ poly) & 0xFFFF\n                else:\n   \
      \                 crc = (crc << 1) & 0xFFFF\n            table.append(crc)\n\
      \        return table\n    \n    def calculate_crc16(self, data):\n        \"\
      \"\"Calculate CRC-16 CCITT for given data\"\"\"\n        crc = 0xFFFF\n    \
      \    for byte in data:\n            tbl_idx = ((crc >> 8) ^ byte) & 0xFF\n \
      \           crc = ((crc << 8) ^ self.crc_table[tbl_idx]) & 0xFFFF\n        return\
      \ crc\n    \n    def handle_msg_in(self, msg):\n        \"\"\"Handle incoming\
      \ messages from GUI/application\"\"\"\n        try:\n            # Handle string\
      \ messages directly\n            if pmt.is_symbol(msg):\n                # Simple\
      \ text message format: \"dst_id:message\"\n                text = pmt.symbol_to_string(msg)\n\
      \                if ':' in text:\n                    parts = text.split(':',\
      \ 1)\n                    try:\n                        dst_id = int(parts[0])\n\
      \                        data = parts[1].encode()\n                        self.tx_queue.put({'dst':\
      \ dst_id, 'data': data, 'type': self.PKT_DATA})\n                        print(f\"\
      [Node {self.node_id}] Queued message to {dst_id}: {parts[1]}\")\n          \
      \          except ValueError:\n                        print(f\"[Node {self.node_id}]\
      \ Invalid destination ID\")\n            \n            # Handle dictionary messages\n\
      \            elif pmt.is_dict(msg):\n                meta = pmt.to_python(msg)\n\
      \                if 'dst' in meta and 'data' in meta:\n                    dst_id\
      \ = meta['dst']\n                    data = meta['data'].encode() if isinstance(meta['data'],\
      \ str) else meta['data']\n                    self.tx_queue.put({'dst': dst_id,\
      \ 'data': data, 'type': self.PKT_DATA})\n                    print(f\"[Node\
      \ {self.node_id}] Queued message to {dst_id}\")\n            \n            #\
      \ Handle pair messages (PDU format)\n            elif pmt.is_pair(msg):\n  \
      \              meta = pmt.to_python(pmt.car(msg))\n                data = pmt.to_python(pmt.cdr(msg))\n\
      \                if isinstance(meta, dict) and 'dst' in meta:\n            \
      \        dst_id = meta['dst']\n                    if isinstance(data, str):\n\
      \                        data = data.encode()\n                    elif isinstance(data,\
      \ list):\n                        data = bytes(data)\n                    self.tx_queue.put({'dst':\
      \ dst_id, 'data': data, 'type': self.PKT_DATA})\n                    print(f\"\
      [Node {self.node_id}] Queued message to {dst_id}\")\n                    \n\
      \        except Exception as e:\n            print(f\"[Node {self.node_id}]\
      \ Error handling msg_in: {e}\")\n    \n    def handle_pdu_in(self, pdu):\n \
      \       \"\"\"Handle incoming PDUs from demodulator\"\"\"\n        try:\n  \
      \          # Extract PDU data\n            if pmt.is_pair(pdu):\n          \
      \      meta = pmt.car(pdu)\n                data = pmt.cdr(pdu)\n          \
      \      \n                # Convert to bytes\n                if pmt.is_u8vector(data):\n\
      \                    print(\"loop run\")\t\n                    rx_bytes = bytes(pmt.u8vector_elements(data))\t\
      \n                    self.rx_queue.put(rx_bytes)\n                elif pmt.is_uniform_vector(data):\n\
      \                    # Handle float32 or other vector types\n              \
      \      elements = pmt.to_python(data)\n                    # Convert to bytes\
      \ (assuming 8-bit symbols)\n                    rx_bytes = bytes([int(x) & 0xFF\
      \ for x in elements])\n                    self.rx_queue.put(rx_bytes)\n   \
      \                 \n        except Exception as e:\n            print(f\"[Node\
      \ {self.node_id}] Error handling pdu_in: {e}\")\n    \n    def create_packet(self,\
      \ dst_id, seq_num, pkt_type, payload=b''):\n        \"\"\"Create a packet with\
      \ headers and CRC\"\"\"\n        packet = bytearray()\n        \n        # Add\
      \ preamble and sync word\n        packet.extend(self.PREAMBLE)\n        packet.extend(self.SYNC_WORD)\n\
      \        \n        # Add header\n        packet.append(self.node_id)  # Source\
      \ ID\n        packet.append(dst_id)         # Destination ID\n        packet.append(seq_num)\
      \        # Sequence number\n        packet.append(pkt_type)       # Packet type\n\
      \        packet.append(len(payload))   # Payload length\n        \n        #\
      \ Add payload\n        if payload:\n            packet.extend(payload[:self.MAX_PAYLOAD])\n\
      \        \n        # Calculate and add CRC16\n        crc_data = bytes(packet[len(self.PREAMBLE)\
      \ + len(self.SYNC_WORD):])\n        crc_val = self.calculate_crc16(crc_data)\n\
      \        packet.extend(struct.pack('>H', crc_val))\n        \n        return\
      \ bytes(packet)\n    \n    def parse_packet(self, data):\n        \"\"\"Parse\
      \ received packet and validate CRC\"\"\"\n        try:\n            # Find sync\
      \ word\n            sync_idx = data.find(self.SYNC_WORD)\n            if sync_idx\
      \ == -1:\n                return None\n            \n            # Check minimum\
      \ packet size\n            start_idx = sync_idx + len(self.SYNC_WORD)\n    \
      \        if len(data) < start_idx + 5 + self.CRC_SIZE:\n                return\
      \ None\n            \n            # Extract header fields\n            src_id\
      \ = data[start_idx]\n            dst_id = data[start_idx + 1]\n            seq_num\
      \ = data[start_idx + 2]\n            pkt_type = data[start_idx + 3]\n      \
      \      payload_len = data[start_idx + 4]\n            \n            # Check\
      \ if we have complete packet\n            total_len = start_idx + 5 + payload_len\
      \ + self.CRC_SIZE\n            if len(data) < total_len:\n                return\
      \ None\n            \n            # Extract payload and CRC\n            payload\
      \ = data[start_idx + 5:start_idx + 5 + payload_len]\n            rx_crc = struct.unpack('>H',\
      \ data[total_len - self.CRC_SIZE:total_len])[0]\n            \n            #\
      \ Verify CRC\n            crc_data = data[start_idx:total_len - self.CRC_SIZE]\n\
      \            calc_crc = self.calculate_crc16(crc_data)\n            \n     \
      \       if rx_crc != calc_crc:\n                self.stats['crc_errors'] +=\
      \ 1\n                print(f\"[Node {self.node_id}] CRC mismatch (expected:\
      \ {calc_crc:04X}, got: {rx_crc:04X})\")\n                return None\n     \
      \       \n            return {\n                'src': src_id,\n           \
      \     'dst': dst_id,\n                'seq': seq_num,\n                'type':\
      \ pkt_type,\n                'payload': payload,\n                'consumed':\
      \ total_len\n            }\n        except Exception as e:\n            print(f\"\
      [Node {self.node_id}] Error parsing packet: {e}\")\n            return None\n\
      \    \n    def tx_handler(self):\n        \"\"\"Thread for handling packet transmission\
      \ with ARQ\"\"\"\n        while self.running:\n            try:\n          \
      \      # Get message from queue (with timeout for thread safety)\n         \
      \       try:\n                    msg = self.tx_queue.get(timeout=0.1)\n   \
      \             except queue.Empty:\n                    continue\n          \
      \      \n                # ALOHA: Random backoff\n                if random.random()\
      \ > self.aloha_prob:\n                    backoff_time = random.uniform(0.1,\
      \ 0.5)\n                    print(f\"[Node {self.node_id}] ALOHA backoff {backoff_time:.2f}s\"\
      )\n                    time.sleep(backoff_time)\n                    # Re-queue\
      \ the message\n                    self.tx_queue.put(msg)\n                \
      \    continue\n                \n                # Prepare packet\n        \
      \        with self.lock:\n                    seq_num = self.seq_num_tx\n  \
      \                  self.seq_num_tx = (self.seq_num_tx + 1) % 256\n         \
      \       \n                packet = self.create_packet(\n                   \
      \ msg['dst'],\n                    seq_num,\n                    msg['type'],\n\
      \                    msg.get('data', b'')\n                )\n             \
      \   \n                # Stop-and-Wait ARQ\n                retries = 0\n   \
      \             ack_received = False\n                \n                while\
      \ retries < self.max_retries and not ack_received:\n                    # Transmit\
      \ packet\n                    print(f\"[Node {self.node_id}] TX: Sending packet\
      \ seq={seq_num} to node {msg['dst']} (attempt {retries + 1})\")\n          \
      \          self.transmit_packet(packet)\n                    self.stats['packets_sent']\
      \ += 1\n                    \n                    if retries > 0:\n        \
      \                self.stats['retransmissions'] += 1\n                    \n\
      \                    # Wait for ACK\n                    ack_key = f\"{msg['dst']}_{seq_num}\"\
      \n                    timeout_time = time.time() + self.timeout\n          \
      \          \n                    while time.time() < timeout_time:\n       \
      \                 try:\n                            ack = self.ack_queue.get(timeout=0.1)\n\
      \                            if ack['key'] == ack_key:\n                   \
      \             ack_received = True\n                                self.stats['acks_received']\
      \ += 1\n                                print(f\"[Node {self.node_id}] TX: ACK\
      \ received for seq={seq_num}\")\n                                break\n   \
      \                     except queue.Empty:\n                            pass\n\
      \                    \n                    if not ack_received:\n          \
      \              retries += 1\n                        if retries < self.max_retries:\n\
      \                            print(f\"[Node {self.node_id}] TX: Timeout, retry\
      \ {retries}/{self.max_retries}\")\n                \n                if not\
      \ ack_received:\n                    print(f\"[Node {self.node_id}] TX: Failed\
      \ to deliver packet seq={seq_num} after {self.max_retries} attempts\")\n   \
      \                 \n            except Exception as e:\n                print(f\"\
      [Node {self.node_id}] TX handler error: {e}\")\n    \n    def rx_handler(self):\n\
      \        \"\"\"Thread for handling packet reception\"\"\"\n        while self.running:\n\
      \            try:\n                # Get received data\n                try:\n\
      \                    rx_data = self.rx_queue.get(timeout=0.1)\n            \
      \    except queue.Empty:\n                    continue\n                \n \
      \               # Add to buffer\n                self.rx_buffer += rx_data\n\
      \                \n                # Try to parse packets from buffer\n    \
      \            while len(self.rx_buffer) > 0:\n                    pkt = self.parse_packet(self.rx_buffer)\n\
      \                    \n                    if pkt is None:\n               \
      \         # No valid packet found, remove first byte and try again\n       \
      \                 if len(self.rx_buffer) > 1:\n                            self.rx_buffer\
      \ = self.rx_buffer[1:]\n                        else:\n                    \
      \        self.rx_buffer = bytes()\n                        continue\n      \
      \              \n                    # Remove processed packet from buffer\n\
      \                    self.rx_buffer = self.rx_buffer[pkt['consumed']:]\n   \
      \                 \n                    # Check if packet is for this node or\
      \ broadcast\n                    if pkt['dst'] != self.node_id and pkt['dst']\
      \ != 0xFF:\n                        print(f\"[Node {self.node_id}] RX: Packet\
      \ not for us (dst={pkt['dst']})\")\n                        continue\n     \
      \               \n                    # Handle based on packet type\n      \
      \              if pkt['type'] == self.PKT_DATA:\n                        self.stats['packets_received']\
      \ += 1\n                        print(f\"[Node {self.node_id}] RX: Data packet\
      \ from node {pkt['src']}, seq={pkt['seq']}\")\n                        \n  \
      \                      # Check for duplicate\n                        is_duplicate\
      \ = False\n                        if pkt['src'] in self.seq_num_rx:\n     \
      \                       if self.seq_num_rx[pkt['src']] == pkt['seq']:\n    \
      \                            print(f\"[Node {self.node_id}] RX: Duplicate packet\
      \ detected\")\n                                is_duplicate = True\n       \
      \                 \n                        self.seq_num_rx[pkt['src']] = pkt['seq']\n\
      \                        \n                        # Send ACK\n            \
      \            ack_packet = self.create_packet(\n                            pkt['src'],\n\
      \                            pkt['seq'],\n                            self.PKT_ACK\n\
      \                        )\n                        print(f\"[Node {self.node_id}]\
      \ RX: Sending ACK for seq={pkt['seq']}\")\n                        self.transmit_packet(ack_packet)\n\
      \                        self.stats['acks_sent'] += 1\n                    \
      \    \n                        # Forward to application if not duplicate\n \
      \                       if not is_duplicate:\n                            self.forward_to_app(pkt['src'],\
      \ pkt['payload'])\n                        \n                    elif pkt['type']\
      \ == self.PKT_ACK:\n                        print(f\"[Node {self.node_id}] RX:\
      \ ACK packet from node {pkt['src']}, seq={pkt['seq']}\")\n                 \
      \       # Process ACK\n                        ack_key = f\"{pkt['src']}_{pkt['seq']}\"\
      \n                        self.ack_queue.put({'key': ack_key})\n           \
      \             \n            except Exception as e:\n                print(f\"\
      [Node {self.node_id}] RX handler error: {e}\")\n    \n    def transmit_packet(self,\
      \ packet):\n        \"\"\"Send packet to physical layer\"\"\"\n        try:\n\
      \            # Convert to PDU format\n            vec = pmt.init_u8vector(len(packet),\
      \ list(packet))\n            pdu = pmt.cons(pmt.PMT_NIL, vec)\n            \n\
      \            # Send to modulator\n            self.message_port_pub(pmt.intern('pdu_out'),\
      \ pdu)\n            \n        except Exception as e:\n            print(f\"\
      [Node {self.node_id}] Error transmitting packet: {e}\")\n    \n    def forward_to_app(self,\
      \ src_id, data):\n        \"\"\"Forward received data to application/GUI\"\"\
      \"\n        try:\n            # Decode message\n            message = data.decode('utf-8',\
      \ errors='ignore')\n            \n            # Create formatted output string\n\
      \            output = f\"[From Node {src_id}]: {message}\"\n            \n \
      \           # Send as simple string message\n            msg = pmt.intern(output)\n\
      \            self.message_port_pub(pmt.intern('msg_out'), msg)\n           \
      \ \n            # Also send as dictionary for more complex processing\n    \
      \        meta = pmt.make_dict()\n            meta = pmt.dict_add(meta, pmt.intern(\"\
      src\"), pmt.from_long(src_id))\n            meta = pmt.dict_add(meta, pmt.intern(\"\
      data\"), pmt.intern(message))\n            \n            print(f\"[Node {self.node_id}]\
      \ Message delivered: {output}\")\n            \n        except Exception as\
      \ e:\n            print(f\"[Node {self.node_id}] Error forwarding to app: {e}\"\
      )\n    \n    def work(self, input_items, output_items):\n        \"\"\"Main\
      \ work function (not used for message passing blocks)\"\"\"\n        return\
      \ 0\n    \n    def stop(self):\n        \"\"\"Clean shutdown\"\"\"\n       \
      \ print(f\"\\n[Node {self.node_id}] Statistics:\")\n        print(f\"  Packets\
      \ sent: {self.stats['packets_sent']}\")\n        print(f\"  Packets received:\
      \ {self.stats['packets_received']}\")\n        print(f\"  ACKs sent: {self.stats['acks_sent']}\"\
      )\n        print(f\"  ACKs received: {self.stats['acks_received']}\")\n    \
      \    print(f\"  Retransmissions: {self.stats['retransmissions']}\")\n      \
      \  print(f\"  CRC errors: {self.stats['crc_errors']}\")\n        \n        self.running\
      \ = False\n        if self.tx_thread.is_alive():\n            self.tx_thread.join()\n\
      \        if self.rx_thread.is_alive():\n            self.rx_thread.join()\n\
      \        return True\n"
    affinity: ''
    alias: ''
    aloha_prob: '0.5'
    comment: ''
    max_retries: '3'
    maxoutbuf: '0'
    minoutbuf: '0'
    node_id: '2'
    timeout: '1'
  states:
    _io_cache: ('Mesh Packet Comm', 'blk', [('node_id', '1'), ('aloha_prob', '0.3'),
      ('timeout', '1.0'), ('max_retries', '3')], [('msg_in', 'message', 1), ('pdu_in',
      'message', 1)], [('pdu_out', 'message', 1), ('msg_out', 'message', 1)], '\n    Mesh
      Network Packet Communication Block\n    Handles packet transmission/reception
      with Stop-and-Wait ARQ\n    ', ['aloha_prob', 'max_retries', 'node_id', 'timeout'])
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [888, 936.0]
    rotation: 0
    state: enabled
- name: epy_block_1
  id: epy_block
  parameters:
    _source_code: "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport numpy\
      \ as np\nfrom gnuradio import gr\nimport pmt\n\nclass pdu_to_bitstream(gr.sync_block):\n\
      \    \"\"\"\n    Converts PDU messages to a framed bitstream.\n    Frame format:\
      \ [SYNC_WORD (4 bytes)] [LENGTH (2 bytes)] [DATA (N bytes)]\n    Each byte is\
      \ unpacked into 8 bits (MSB first).\n    \"\"\"\n    def __init__(self, sync_word=0x1ACFFC1D):\n\
      \        gr.sync_block.__init__(\n            self,\n            name=\"PDU\
      \ to Bitstream\",\n            in_sig=None,\n            out_sig=[np.uint8]\n\
      \        )\n        \n        self.message_port_register_in(pmt.intern('pdu_in'))\n\
      \        self.set_msg_handler(pmt.intern('pdu_in'), self.handle_pdu)\n     \
      \   \n        self.sync_word = sync_word\n        self.bit_buffer = []\n   \
      \     \n    def handle_pdu(self, pdu):\n        \"\"\"Handle incoming PDU messages\"\
      \"\"\n        # Extract data from PDU (ignore metadata for now)\n        data\
      \ = pmt.cdr(pdu)\n        \n        # Convert PMT vector to numpy array\n  \
      \      if pmt.is_u8vector(data):\n            data_bytes = np.array(pmt.u8vector_elements(data),\
      \ dtype=np.uint8)\n        else:\n            return\n        \n        # Build\
      \ frame: [SYNC][LENGTH][DATA]\n        frame = []\n        \n        # Add sync\
      \ word (4 bytes, big-endian)\n        sync_bytes = np.array([\n            (self.sync_word\
      \ >> 24) & 0xFF,\n            (self.sync_word >> 16) & 0xFF,\n            (self.sync_word\
      \ >> 8) & 0xFF,\n            self.sync_word & 0xFF\n        ], dtype=np.uint8)\n\
      \        frame.extend(sync_bytes)\n        \n        # Add length (2 bytes,\
      \ big-endian)\n        length = len(data_bytes)\n        length_bytes = np.array([\n\
      \            (length >> 8) & 0xFF,\n            length & 0xFF\n        ], dtype=np.uint8)\n\
      \        frame.extend(length_bytes)\n        \n        # Add data\n        frame.extend(data_bytes)\n\
      \        \n        # Convert frame to numpy array and unpack to bits\n     \
      \   frame_array = np.array(frame, dtype=np.uint8)\n        bits = np.unpackbits(frame_array)\n\
      \        \n        # Add bits to buffer\n        self.bit_buffer.extend(bits.tolist())\n\
      \    \n    def work(self, input_items, output_items):\n        \"\"\"Output\
      \ buffered bits\"\"\"\n        out = output_items[0]\n        \n        # Determine\
      \ how many bits to output\n        n_output = min(len(self.bit_buffer), len(out))\n\
      \        \n        if n_output > 0:\n            # Copy bits to output\n   \
      \         out[:n_output] = self.bit_buffer[:n_output]\n            # Remove\
      \ outputted bits from buffer\n            self.bit_buffer = self.bit_buffer[n_output:]\n\
      \            \n        return n_output"
    affinity: ''
    alias: ''
    comment: ''
    maxoutbuf: '0'
    minoutbuf: '0'
    sync_word: '0x1ACFFC1D'
  states:
    _io_cache: '(''PDU to Bitstream'', ''pdu_to_bitstream'', [(''sync_word'', ''449838109'')],
      [(''pdu_in'', ''message'', 1)], [(''0'', ''byte'', 1)], ''\n    Converts PDU
      messages to a framed bitstream.\n    Frame format: [SYNC_WORD (4 bytes)] [LENGTH
      (2 bytes)] [DATA (N bytes)]\n    Each byte is unpacked into 8 bits (MSB first).\n    '',
      [''sync_word''])'
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [840, 200.0]
    rotation: 0
    state: enabled
- name: epy_block_1_0
  id: epy_block
  parameters:
    _source_code: "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport numpy\
      \ as np\nfrom gnuradio import gr\nimport pmt\n\nclass pdu_to_bitstream(gr.sync_block):\n\
      \    \"\"\"\n    Converts PDU messages to a framed bitstream.\n    Frame format:\
      \ [SYNC_WORD (4 bytes)] [LENGTH (2 bytes)] [DATA (N bytes)]\n    Each byte is\
      \ unpacked into 8 bits (MSB first).\n    \"\"\"\n    def __init__(self, sync_word=0x1ACFFC1D):\n\
      \        gr.sync_block.__init__(\n            self,\n            name=\"PDU\
      \ to Bitstream\",\n            in_sig=None,\n            out_sig=[np.uint8]\n\
      \        )\n        \n        self.message_port_register_in(pmt.intern('pdu_in'))\n\
      \        self.set_msg_handler(pmt.intern('pdu_in'), self.handle_pdu)\n     \
      \   \n        self.sync_word = sync_word\n        self.bit_buffer = []\n   \
      \     \n    def handle_pdu(self, pdu):\n        \"\"\"Handle incoming PDU messages\"\
      \"\"\n        # Extract data from PDU (ignore metadata for now)\n        data\
      \ = pmt.cdr(pdu)\n        \n        # Convert PMT vector to numpy array\n  \
      \      if pmt.is_u8vector(data):\n            data_bytes = np.array(pmt.u8vector_elements(data),\
      \ dtype=np.uint8)\n        else:\n            return\n        \n        # Build\
      \ frame: [SYNC][LENGTH][DATA]\n        frame = []\n        \n        # Add sync\
      \ word (4 bytes, big-endian)\n        sync_bytes = np.array([\n            (self.sync_word\
      \ >> 24) & 0xFF,\n            (self.sync_word >> 16) & 0xFF,\n            (self.sync_word\
      \ >> 8) & 0xFF,\n            self.sync_word & 0xFF\n        ], dtype=np.uint8)\n\
      \        frame.extend(sync_bytes)\n        \n        # Add length (2 bytes,\
      \ big-endian)\n        length = len(data_bytes)\n        length_bytes = np.array([\n\
      \            (length >> 8) & 0xFF,\n            length & 0xFF\n        ], dtype=np.uint8)\n\
      \        frame.extend(length_bytes)\n        \n        # Add data\n        frame.extend(data_bytes)\n\
      \        \n        # Convert frame to numpy array and unpack to bits\n     \
      \   frame_array = np.array(frame, dtype=np.uint8)\n        bits = np.unpackbits(frame_array)\n\
      \        \n        # Add bits to buffer\n        self.bit_buffer.extend(bits.tolist())\n\
      \    \n    def work(self, input_items, output_items):\n        \"\"\"Output\
      \ buffered bits\"\"\"\n        out = output_items[0]\n        \n        # Determine\
      \ how many bits to output\n        n_output = min(len(self.bit_buffer), len(out))\n\
      \        \n        if n_output > 0:\n            # Copy bits to output\n   \
      \         out[:n_output] = self.bit_buffer[:n_output]\n            # Remove\
      \ outputted bits from buffer\n            self.bit_buffer = self.bit_buffer[n_output:]\n\
      \            \n        return n_output"
    affinity: ''
    alias: ''
    comment: ''
    maxoutbuf: '0'
    minoutbuf: '0'
    sync_word: '0x1ACFFC1D'
  states:
    _io_cache: '(''PDU to Bitstream'', ''pdu_to_bitstream'', [(''sync_word'', ''449838109'')],
      [(''pdu_in'', ''message'', 1)], [(''0'', ''byte'', 1)], ''\n    Converts PDU
      messages to a framed bitstream.\n    Frame format: [SYNC_WORD (4 bytes)] [LENGTH
      (2 bytes)] [DATA (N bytes)]\n    Each byte is unpacked into 8 bits (MSB first).\n    '',
      [''sync_word''])'
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [440, 700.0]
    rotation: 180
    state: enabled
- name: epy_block_2
  id: epy_block
  parameters:
    _source_code: "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport numpy\
      \ as np\nfrom gnuradio import gr\nimport pmt\n\nclass bitstream_to_pdu(gr.sync_block):\n\
      \    \"\"\"\n    Converts a framed bitstream back to PDU messages.\n    Searches\
      \ for sync word and reconstructs PDUs based on length field.\n    Frame format:\
      \ [SYNC_WORD (4 bytes)] [LENGTH (2 bytes)] [DATA (N bytes)]\n    \"\"\"\n  \
      \  def __init__(self, sync_word=0x1ACFFC1D, threshold=0):\n        gr.sync_block.__init__(\n\
      \            self,\n            name=\"Bitstream to PDU\",\n            in_sig=[np.uint8],\n\
      \            out_sig=None\n        )\n        \n        self.message_port_register_out(pmt.intern('pdu_out'))\n\
      \        \n        self.sync_word = sync_word\n        self.threshold = threshold\
      \  # Number of bit errors allowed in sync\n        \n        # Convert sync\
      \ word to bit pattern\n        sync_bytes = np.array([\n            (sync_word\
      \ >> 24) & 0xFF,\n            (sync_word >> 16) & 0xFF,\n            (sync_word\
      \ >> 8) & 0xFF,\n            sync_word & 0xFF\n        ], dtype=np.uint8)\n\
      \        self.sync_bits = np.unpackbits(sync_bytes)\n        \n        self.bit_buffer\
      \ = []\n        self.state = 'SEARCH'  # States: SEARCH, READ_LENGTH, READ_DATA\n\
      \        self.pdu_length = 0\n        self.bits_needed = 0\n        \n    def\
      \ correlate_sync(self, bits):\n        \"\"\"Check if bits match sync word (with\
      \ threshold)\"\"\"\n        if len(bits) < len(self.sync_bits):\n          \
      \  return False\n        \n        errors = np.sum(bits[:len(self.sync_bits)]\
      \ != self.sync_bits)\n        return errors <= self.threshold\n    \n    def\
      \ work(self, input_items, output_items):\n        \"\"\"Process input bitstream\
      \ and reconstruct PDUs\"\"\"\n        in0 = input_items[0]\n        n_input\
      \ = len(in0)\n        \n        # Add incoming bits to buffer\n        self.bit_buffer.extend(in0[:n_input].tolist())\n\
      \        \n        # Process buffer based on current state\n        while True:\n\
      \            if self.state == 'SEARCH':\n                # Search for sync word\n\
      \                if len(self.bit_buffer) >= len(self.sync_bits):\n         \
      \           if self.correlate_sync(np.array(self.bit_buffer[:len(self.sync_bits)])):\n\
      \                        # Found sync word, remove it from buffer\n        \
      \                self.bit_buffer = self.bit_buffer[len(self.sync_bits):]\n \
      \                       self.state = 'READ_LENGTH'\n                    else:\n\
      \                        # Shift by one bit and continue searching\n       \
      \                 self.bit_buffer.pop(0)\n                else:\n          \
      \          break  # Not enough bits yet\n                    \n            elif\
      \ self.state == 'READ_LENGTH':\n                # Need 16 bits (2 bytes) for\
      \ length\n                if len(self.bit_buffer) >= 16:\n                 \
      \   # Extract length bits and convert to bytes\n                    length_bits\
      \ = np.array(self.bit_buffer[:16], dtype=np.uint8)\n                    length_bytes\
      \ = np.packbits(length_bits)\n                    self.pdu_length = (int(length_bytes[0])\
      \ << 8) | int(length_bytes[1])\n                    \n                    #\
      \ Remove length bits from buffer\n                    self.bit_buffer = self.bit_buffer[16:]\n\
      \                    \n                    # Calculate bits needed for data\n\
      \                    self.bits_needed = self.pdu_length * 8\n              \
      \      self.state = 'READ_DATA'\n                else:\n                   \
      \ break  # Not enough bits yet\n                    \n            elif self.state\
      \ == 'READ_DATA':\n                # Check if we have all data bits\n      \
      \          if len(self.bit_buffer) >= self.bits_needed:\n                  \
      \  # Extract data bits\n                    data_bits = np.array(self.bit_buffer[:self.bits_needed],\
      \ dtype=np.uint8)\n                    self.bit_buffer = self.bit_buffer[self.bits_needed:]\n\
      \                    \n                    # Pack bits back into bytes\n   \
      \                 data_bytes = np.packbits(data_bits)\n                    \n\
      \                    # Create and send PDU (with empty metadata)\n         \
      \           pdu_vector = pmt.init_u8vector(len(data_bytes), data_bytes.tolist())\n\
      \                    pdu = pmt.cons(pmt.make_dict(), pdu_vector)\n         \
      \           self.message_port_pub(pmt.intern('pdu_out'), pdu)\n            \
      \        \n                    # Go back to searching for next frame\n     \
      \               self.state = 'SEARCH'\n                else:\n             \
      \       break  # Not enough bits yet\n        \n        return n_input\n"
    affinity: ''
    alias: ''
    comment: ''
    maxoutbuf: '0'
    minoutbuf: '0'
    sync_word: '0x1ACFFC1D'
    threshold: '1'
  states:
    _io_cache: '(''Bitstream to PDU'', ''bitstream_to_pdu'', [(''sync_word'', ''449838109''),
      (''threshold'', ''0'')], [(''0'', ''byte'', 1)], [(''pdu_out'', ''message'',
      1)], ''\n    Converts a framed bitstream back to PDU messages.\n    Searches
      for sync word and reconstructs PDUs based on length field.\n    Frame format:
      [SYNC_WORD (4 bytes)] [LENGTH (2 bytes)] [DATA (N bytes)]\n    '', [''sync_word'',
      ''threshold''])'
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [920, 696.0]
    rotation: 180
    state: enabled
- name: epy_block_2_0
  id: epy_block
  parameters:
    _source_code: "#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport numpy\
      \ as np\nfrom gnuradio import gr\nimport pmt\n\nclass bitstream_to_pdu(gr.sync_block):\n\
      \    \"\"\"\n    Converts a framed bitstream back to PDU messages.\n    Searches\
      \ for sync word and reconstructs PDUs based on length field.\n    Frame format:\
      \ [SYNC_WORD (4 bytes)] [LENGTH (2 bytes)] [DATA (N bytes)]\n    \"\"\"\n  \
      \  def __init__(self, sync_word=0x1ACFFC1D, threshold=0):\n        gr.sync_block.__init__(\n\
      \            self,\n            name=\"Bitstream to PDU\",\n            in_sig=[np.uint8],\n\
      \            out_sig=None\n        )\n        \n        self.message_port_register_out(pmt.intern('pdu_out'))\n\
      \        \n        self.sync_word = sync_word\n        self.threshold = threshold\
      \  # Number of bit errors allowed in sync\n        \n        # Convert sync\
      \ word to bit pattern\n        sync_bytes = np.array([\n            (sync_word\
      \ >> 24) & 0xFF,\n            (sync_word >> 16) & 0xFF,\n            (sync_word\
      \ >> 8) & 0xFF,\n            sync_word & 0xFF\n        ], dtype=np.uint8)\n\
      \        self.sync_bits = np.unpackbits(sync_bytes)\n        \n        self.bit_buffer\
      \ = []\n        self.state = 'SEARCH'  # States: SEARCH, READ_LENGTH, READ_DATA\n\
      \        self.pdu_length = 0\n        self.bits_needed = 0\n        \n    def\
      \ correlate_sync(self, bits):\n        \"\"\"Check if bits match sync word (with\
      \ threshold)\"\"\"\n        if len(bits) < len(self.sync_bits):\n          \
      \  return False\n        \n        errors = np.sum(bits[:len(self.sync_bits)]\
      \ != self.sync_bits)\n        return errors <= self.threshold\n    \n    def\
      \ work(self, input_items, output_items):\n        \"\"\"Process input bitstream\
      \ and reconstruct PDUs\"\"\"\n        in0 = input_items[0]\n        n_input\
      \ = len(in0)\n        \n        # Add incoming bits to buffer\n        self.bit_buffer.extend(in0[:n_input].tolist())\n\
      \        \n        # Process buffer based on current state\n        while True:\n\
      \            if self.state == 'SEARCH':\n                # Search for sync word\n\
      \                if len(self.bit_buffer) >= len(self.sync_bits):\n         \
      \           if self.correlate_sync(np.array(self.bit_buffer[:len(self.sync_bits)])):\n\
      \                        # Found sync word, remove it from buffer\n        \
      \                self.bit_buffer = self.bit_buffer[len(self.sync_bits):]\n \
      \                       self.state = 'READ_LENGTH'\n                    else:\n\
      \                        # Shift by one bit and continue searching\n       \
      \                 self.bit_buffer.pop(0)\n                else:\n          \
      \          break  # Not enough bits yet\n                    \n            elif\
      \ self.state == 'READ_LENGTH':\n                # Need 16 bits (2 bytes) for\
      \ length\n                if len(self.bit_buffer) >= 16:\n                 \
      \   # Extract length bits and convert to bytes\n                    length_bits\
      \ = np.array(self.bit_buffer[:16], dtype=np.uint8)\n                    length_bytes\
      \ = np.packbits(length_bits)\n                    self.pdu_length = (int(length_bytes[0])\
      \ << 8) | int(length_bytes[1])\n                    \n                    #\
      \ Remove length bits from buffer\n                    self.bit_buffer = self.bit_buffer[16:]\n\
      \                    \n                    # Calculate bits needed for data\n\
      \                    self.bits_needed = self.pdu_length * 8\n              \
      \      self.state = 'READ_DATA'\n                else:\n                   \
      \ break  # Not enough bits yet\n                    \n            elif self.state\
      \ == 'READ_DATA':\n                # Check if we have all data bits\n      \
      \          if len(self.bit_buffer) >= self.bits_needed:\n                  \
      \  # Extract data bits\n                    data_bits = np.array(self.bit_buffer[:self.bits_needed],\
      \ dtype=np.uint8)\n                    self.bit_buffer = self.bit_buffer[self.bits_needed:]\n\
      \                    \n                    # Pack bits back into bytes\n   \
      \                 data_bytes = np.packbits(data_bits)\n                    \n\
      \                    # Create and send PDU (with empty metadata)\n         \
      \           pdu_vector = pmt.init_u8vector(len(data_bytes), data_bytes.tolist())\n\
      \                    pdu = pmt.cons(pmt.make_dict(), pdu_vector)\n         \
      \           self.message_port_pub(pmt.intern('pdu_out'), pdu)\n            \
      \        \n                    # Go back to searching for next frame\n     \
      \               self.state = 'SEARCH'\n                else:\n             \
      \       break  # Not enough bits yet\n        \n        return n_input\n"
    affinity: ''
    alias: ''
    comment: ''
    maxoutbuf: '0'
    minoutbuf: '0'
    sync_word: '0x1ACFFC1D'
    threshold: '1'
  states:
    _io_cache: '(''Bitstream to PDU'', ''bitstream_to_pdu'', [(''sync_word'', ''449838109''),
      (''threshold'', ''0'')], [(''0'', ''byte'', 1)], [(''pdu_out'', ''message'',
      1)], ''\n    Converts a framed bitstream back to PDU messages.\n    Searches
      for sync word and reconstructs PDUs based on length field.\n    Frame format:
      [SYNC_WORD (4 bytes)] [LENGTH (2 bytes)] [DATA (N bytes)]\n    '', [''sync_word'',
      ''threshold''])'
    bus_sink: false
    bus_source: false
    bus_structure: null
    coordinate: [368, 480.0]
    rotation: 0
    state: enabled

connections:
- [blocks_message_strobe_0, strobe, epy_block_0, msg_in]
- [blocks_message_strobe_0_0, strobe, epy_block_0_0, msg_in]
- [epy_block_0, msg_out, blocks_message_debug_0_0, print]
- [epy_block_0, pdu_out, epy_block_1, pdu_in]
- [epy_block_0_0, msg_out, blocks_message_debug_0, print]
- [epy_block_0_0, pdu_out, epy_block_1_0, pdu_in]
- [epy_block_1, '0', epy_block_2, '0']
- [epy_block_1_0, '0', epy_block_2_0, '0']
- [epy_block_2, pdu_out, epy_block_0_0, pdu_in]
- [epy_block_2_0, pdu_out, epy_block_0, pdu_in]

metadata:
  file_format: 1
  grc_version: 3.10.12.0
